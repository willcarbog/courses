WEBVTT

00:00:01.360 --> 00:00:05.400
If our objective is to keep the
mean squared estimation

00:00:05.400 --> 00:00:09.490
error small, then the best
possible estimator is the

00:00:09.490 --> 00:00:11.590
conditional expectation.

00:00:11.590 --> 00:00:12.920
But sometimes the conditional

00:00:12.920 --> 00:00:15.820
expectation is hard to calculate.

00:00:15.820 --> 00:00:18.410
Maybe we're missing the
details of the various

00:00:18.410 --> 00:00:20.340
probability distributions.

00:00:20.340 --> 00:00:24.080
Or maybe we have the
distributions that we need but

00:00:24.080 --> 00:00:26.690
the formulas are complicated.

00:00:26.690 --> 00:00:29.070
After all, the conditional
expectation can be a

00:00:29.070 --> 00:00:33.220
complicated non-linear function
of the observations.

00:00:33.220 --> 00:00:36.970
For this reason, we may want to
consider an estimator that

00:00:36.970 --> 00:00:40.910
has a simpler structure, an
estimator that is a linear

00:00:40.910 --> 00:00:42.700
function of the data.

00:00:42.700 --> 00:00:46.700
And then, within this class of
estimators, find the one that

00:00:46.700 --> 00:00:51.410
results in the smallest possible
mean squared error.

00:00:51.410 --> 00:00:54.870
In this lecture we will
formulate this linear least

00:00:54.870 --> 00:00:58.560
squares estimation problem
and then solve it.

00:00:58.560 --> 00:01:01.940
We will see that the solution
is given by a simple formula

00:01:01.940 --> 00:01:06.910
that involves only the means,
variances, and covariances of

00:01:06.910 --> 00:01:09.390
the random variables involved.

00:01:09.390 --> 00:01:13.060
Because of the simplicity of the
method, linear estimators

00:01:13.060 --> 00:01:16.340
are used quite often, especially
in systems where

00:01:16.340 --> 00:01:20.289
estimates need to be computed
quickly in real time as

00:01:20.289 --> 00:01:23.580
observations are obtained.

00:01:23.580 --> 00:01:26.710
We will look into some of the
mathematical properties of the

00:01:26.710 --> 00:01:30.650
linear least mean squares
estimator and the associated

00:01:30.650 --> 00:01:34.200
mean squared error, revisit an
example from the previous

00:01:34.200 --> 00:01:37.820
lecture, and finally close with
some comments on the ways

00:01:37.820 --> 00:01:39.759
that this estimator
can be used.
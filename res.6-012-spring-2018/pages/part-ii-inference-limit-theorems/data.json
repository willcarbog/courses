
{
  "title":"Part II: Inference \u0026 Limit Theorems",
  "content":"The videos in Part II describe the laws of large numbers and introduce the main tools of Bayesian inference methods.\nThe textbook for this subject is Bertsekas, Dimitri, and John Tsitsiklis. Introduction to Probability. 2nd ed. Athena Scientific, 2008. ISBN: 9781886529236.\nThe authors have made this Selected Summary Material (PDF) available for OCW users. L = Lecture Content\nS = Supplemental Content\nSES # \u0026amp; TOPICS SLIDES Lecture 14: Introduction to Bayesian Inference › View Lecture Videos\nL14.1 Lecture Overview\nL14.2 Overview of some Application Domains\nL14.3 Types of Inference Problems\nL14.4 The Bayesian Inference Framework\nL14.5 Discrete Parameter, Discrete Observation\nL14.6 Discrete Parameter, Continuous Observation\nL14.7 Continuous Parameter, Continuous Observation\nL14.8 Inferring the Unknown Bias of a Coin and the Beta Distribution\nL14.9 Inferring the Unknown Bias of a Coin—Point Estimates\nL14.10 Summary\nS14.1 The Beta Formula\nLecture 14 Slides (PDF - 2.2MB)\nLecture 14 Slides Annotated (PDF - 1.3MB)\nLecture 15: Linear Models With Normal Noise › View Lecture Videos\nL15.1 Lecture Overview\nL15.2 Recognizing Normal PDFs\nL15.3 Estimating a Normal Random Variable in the Presence of Additive Noise\nL15.4 The Case of Multiple Observations\nL15.5 The Mean Squared Error\nL15.6 Multiple Parameters; Trajectory Estimation\nL15.7 Linear Normal Models\nL15.8 Trajectory Estimation Illustration\nLecture 15 Slides (PDF - 1.8MB)\nLecture 15 Slides Annotated (PDF - 1.8MB)\nLecture 16: Least Mean Squares (LMS) Estimation › View Lecture Videos\nL16.1 Lecture Overview\nL16.2 LMS Estimation in the Absence of Observations\nL16.3 LMS Estimation of One Random Variable Based on Another\nL16.4 LMS Performance Evaluation\nL16.5 Example: The LMS Estimate\nL16.6 Example Continued: LMS Performance Evaluation\nL16.7 LMS Estimation with Multiple Observations or Unknowns\nL16.8 Properties of the LMS Estimation Error\nLecture 16 Slides (PDF - 1.0MB)\nLecture 16 Slides Annotated (PDF - 1.2MB)\nLecture 17: Linear Least Mean Squares (LLMS) Estimation › View Lecture Videos\nL17.1 Lecture Overview\nL17.2 LLMS Formulation\nL17.3 Solution to the LLMS Problem\nL17.4 Remarks on the LLMS Solution and on the Error Variance\nL17.5 LLMS Example\nL17.6 LLMS for Inferring the Parameter of a Coin\nL17.7 LLMS with Multiple Observations\nL17.8 The Simplest LLMS Example with Multiple Observations\nL17.9 The Representation of the Data Matters in LLMS\nLecture 17 Slides (PDF - 1.0MB)\nLecture 17 Slides Annotated (PDF - 1.2MB)\nLecture 18: Inequalities, Convergence, and the Weak Law of Large Numbers › View Lecture Videos\nL18.1 Lecture Overview\nL18.2 The Markov Inequality\nL18.3 The Chebyshev Inequality\nL18.4 The Weak Law of Large Numbers\nL18.5 Polling\nL18.6 Convergence in Probability\nL18.7 Convergence in Probability Examples\nL18.8 Related Topics\nS18.1 Convergence in Probability of the Sum of Two Random Variables\nS18.2 Jensen\u0026rsquo;s Inequality\nS18.3 Hoeffding\u0026rsquo;s Inequality\nLecture 18 Slides (PDF - 1.3MB)\nLecture 18 Slides Annotated (PDF - 1.9MB)\nLecture 19: The Central Limit Theorem (CLT) › View Lecture Videos\nL19.1 Lecture Overview\nL19.2 The Central Limit Theorem\nL19.3 Discussion of the CLT\nL19.4 Illustration of the CLT\nL19.5 CLT Examples\nL19.6 Normal Approximation to the Binomial\nL19.7 Polling Revisited\nLecture 19 Slides (PDF - 2.1MB)\nLecture 19 Slides Annotated (PDF - 2.0MB)\nLecture 20: An Introduction to Classical Statistics › View Lecture Videos\nL20.1 Lecture Overview\nL20.2 Overview of the Classical Statistical Framework\nL20.3 The Sample Mean and Some Terminology\nL20.4 On the Mean Squared Error of an Estimator\nL20.5 Confidence Intervals\nL20.6 Confidence Intervals for the Estimation of the Mean\nL20.7 Confidence Intervals for the Mean, When the Variance is Unknown\nL20.8 Other Natural Estimators\nL20.9 Maximum Likelihood Estimation\nL20.10 Maximum Likelihood Estimation Examples\nLecture 20 Slides (PDF - 1.3MB)\nLecture 20 Slides Annotated\n"}



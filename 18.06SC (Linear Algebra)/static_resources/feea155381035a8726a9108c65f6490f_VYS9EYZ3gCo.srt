1
00:00:04,852 --> 00:00:06,060
DAVID SHIROKOFF: Hi everyone.

2
00:00:06,060 --> 00:00:07,280
Welcome back.

3
00:00:07,280 --> 00:00:10,940
So today we're going to tackle
a problem in complex matrices.

4
00:00:10,940 --> 00:00:13,950
And specifically, we're going
to look at diagonalizing

5
00:00:13,950 --> 00:00:15,280
a complex matrix.

6
00:00:15,280 --> 00:00:17,890
So given this matrix
A, we're asked

7
00:00:17,890 --> 00:00:21,460
to find its eigenvalue matrix
lambda, and its eigenvector

8
00:00:21,460 --> 00:00:23,150
matrix S.

9
00:00:23,150 --> 00:00:25,480
And one thing to note
about this matrix A

10
00:00:25,480 --> 00:00:28,290
is that if we take its
conjugate transpose,

11
00:00:28,290 --> 00:00:30,310
it's actually equal to itself.

12
00:00:30,310 --> 00:00:33,810
So in Professor
Strang's book, he

13
00:00:33,810 --> 00:00:36,170
combines this notation
to be superscript

14
00:00:36,170 --> 00:00:38,856
H to mean conjugate transpose.

15
00:00:38,856 --> 00:00:40,980
So if you were to take the
transpose of this matrix

16
00:00:40,980 --> 00:00:42,510
and then conjugate
all the elements,

17
00:00:42,510 --> 00:00:46,540
you would find that A equals
its conjugate transpose,

18
00:00:46,540 --> 00:00:48,635
and we call this
property Hermitian.

19
00:00:48,635 --> 00:00:50,510
So I'll let you think
about this for a moment

20
00:00:50,510 --> 00:00:51,718
and I'll be back in a second.

21
00:01:03,360 --> 00:01:05,120
OK, welcome back.

22
00:01:05,120 --> 00:01:08,021
So what's the first step in
computing the eigenvectors

23
00:01:08,021 --> 00:01:09,270
and eigenvalues of the matrix?

24
00:01:09,270 --> 00:01:13,670
It's to take a look at the
characteristic equation.

25
00:01:13,670 --> 00:01:16,790
So specifically, we take
det of A minus lambda i.

26
00:01:21,830 --> 00:01:25,080
And quite possibly, the only
thing new with this problem

27
00:01:25,080 --> 00:01:29,130
is that the entries of
the matrix A are complex.

28
00:01:29,130 --> 00:01:34,370
Now, you may have already seen
that lambda's being complex,

29
00:01:34,370 --> 00:01:36,760
but we're going to work
this out explicitly.

30
00:01:36,760 --> 00:01:38,700
So if I take the
determinant, we get

31
00:01:38,700 --> 00:01:45,280
det of 2 minus lambda, 3 minus
lambda, we have 1 minus i,

32
00:01:45,280 --> 00:01:46,000
1 plus i.

33
00:01:49,720 --> 00:01:50,950
We want to set this to 0.

34
00:01:53,664 --> 00:01:55,455
This then gives us a
polynomial for lambda.

35
00:02:02,630 --> 00:02:09,460
1 plus i, 1 minus i,
set it equal to 0.

36
00:02:09,460 --> 00:02:11,869
We can expand out this term.

37
00:02:11,869 --> 00:02:15,980
You get 6 minus 5 lambda
plus lambda squared.

38
00:02:19,150 --> 00:02:21,540
These two terms you'll
note are complex conjugates

39
00:02:21,540 --> 00:02:22,520
of each other.

40
00:02:22,520 --> 00:02:24,900
This tends to make
things simple.

41
00:02:24,900 --> 00:02:30,610
So we have minus 1 minus i
squared is going to give us 2.

42
00:02:30,610 --> 00:02:32,680
Because they're
differences of squares,

43
00:02:32,680 --> 00:02:36,846
the cross terms
involving i cancel,

44
00:02:36,846 --> 00:02:38,470
and we get the
characteristic equation.

45
00:02:43,570 --> 00:02:49,259
Lambda squared minus 5
lambda plus 4 equals 0.

46
00:02:49,259 --> 00:02:51,300
And specifically, we can
factorize this equation.

47
00:02:54,530 --> 00:03:00,360
We see that there's
roots of minus 1--

48
00:03:00,360 --> 00:03:02,750
or factorizes into
factors of lambda minus 1

49
00:03:02,750 --> 00:03:08,690
and lambda minus 4, which then
give us roots of lambda is 1

50
00:03:08,690 --> 00:03:10,390
and lambda is 4.

51
00:03:10,390 --> 00:03:12,890
So when one curious
point to note

52
00:03:12,890 --> 00:03:15,590
is that the eigenvalues
are real in this case.

53
00:03:15,590 --> 00:03:18,230
1 and 4 are real, whereas the
matrix that we started with

54
00:03:18,230 --> 00:03:19,430
was complex.

55
00:03:19,430 --> 00:03:22,720
And this is a general property
of Hermitian matrices.

56
00:03:22,720 --> 00:03:25,020
So even though they might
be complex matrices,

57
00:03:25,020 --> 00:03:29,290
Hermitian matrices always
have real eigenvalues.

58
00:03:29,290 --> 00:03:33,650
So this is the first step when
asked to diagonalize a matrix.

59
00:03:33,650 --> 00:03:36,030
The second step is to
find the eigenvectors.

60
00:03:45,195 --> 00:03:46,570
And to do that
what we have to do

61
00:03:46,570 --> 00:03:49,480
is we have to look at
the cases for lambda

62
00:03:49,480 --> 00:03:52,577
equals 1 and lambda
is equal 4 separately.

63
00:03:52,577 --> 00:03:54,910
So let's first look at the
case of lambda is equal to 1.

64
00:03:59,960 --> 00:04:02,950
And specifically, we're going
to be looking for a vector such

65
00:04:02,950 --> 00:04:13,210
that A minus lambda*I
times the vector v is 0.

66
00:04:13,210 --> 00:04:14,670
And if we've done
things properly,

67
00:04:14,670 --> 00:04:20,720
this matrix A minus
lambda*I should be singular.

68
00:04:20,720 --> 00:04:25,470
So if we take A minus
lambda*I, we're going to get 1,

69
00:04:25,470 --> 00:04:32,290
1 minus i; 1 plus
i, 3 minus 1 is 2.

70
00:04:32,290 --> 00:04:37,410
And I'll write out components
of v, which are v_1 and v_2.

71
00:04:37,410 --> 00:04:40,290
And we want this to be 0.

72
00:04:40,290 --> 00:04:46,380
And you'll note that it's almost
always the case that when we

73
00:04:46,380 --> 00:04:49,540
work out A minus lambda*I,
the second row is going to be

74
00:04:49,540 --> 00:04:52,050
a constant multiple
of the first row.

75
00:04:52,050 --> 00:04:56,090
And this must be the case
because these two rows must be

76
00:04:56,090 --> 00:04:59,040
linearly dependent on each other
for the matrix A minus lambda*I

77
00:04:59,040 --> 00:05:00,777
to be singular.

78
00:05:00,777 --> 00:05:02,360
So if you look at
this you might think

79
00:05:02,360 --> 00:05:04,380
that these two rows
aren't necessarily

80
00:05:04,380 --> 00:05:06,720
linearly independent.

81
00:05:06,720 --> 00:05:09,740
But the point is that there's
complex numbers involved.

82
00:05:09,740 --> 00:05:12,520
And indeed, actually if we
were to multiply this first row

83
00:05:12,520 --> 00:05:16,990
by 1 plus lambda, we would
get 1 plus lambda and 2.

84
00:05:16,990 --> 00:05:19,940
And you note that that's
exactly the second row.

85
00:05:19,940 --> 00:05:22,640
So this second row is
actually 1 plus lambda times

86
00:05:22,640 --> 00:05:23,880
the first row.

87
00:05:23,880 --> 00:05:25,550
So these rows are
actually linearly

88
00:05:25,550 --> 00:05:28,140
dependent on each other.

89
00:05:28,140 --> 00:05:30,820
So what values of v_1
and v_2 can we take?

90
00:05:30,820 --> 00:05:34,210
Well, we just need to make
this top row multiplied

91
00:05:34,210 --> 00:05:36,341
by v_1 and v_2 equal to 0.

92
00:05:36,341 --> 00:05:38,590
And then because the second
row is a constant multiple

93
00:05:38,590 --> 00:05:40,490
of the first row, we're
automatically guaranteed

94
00:05:40,490 --> 00:05:41,781
that the second equation holds.

95
00:05:44,790 --> 00:05:48,910
So just by looking
at it, I'm going

96
00:05:48,910 --> 00:05:57,260
to take v_1 is equal to 1
minus i, and v_2 is negative 1.

97
00:05:57,260 --> 00:06:02,290
So we see that 1 times 1 minus
i minus 1 times 1 minus i

98
00:06:02,290 --> 00:06:03,810
is going to give us 0.

99
00:06:03,810 --> 00:06:05,211
So this is one solution.

100
00:06:05,211 --> 00:06:07,460
And of course, we can take
any constant multiple times

101
00:06:07,460 --> 00:06:08,880
this eigenvector,
and that's also

102
00:06:08,880 --> 00:06:10,004
going to be an eigenvector.

103
00:06:14,810 --> 00:06:16,610
So I'll just write this out.

104
00:06:16,610 --> 00:06:21,630
1 minus i, minus 1 is the
eigenvector for lambda

105
00:06:21,630 --> 00:06:24,640
is equal to 1.

106
00:06:24,640 --> 00:06:29,660
For lambda is equal to 4,
again, A minus lambda*I is going

107
00:06:29,660 --> 00:06:37,620
to give us negative 2,
1 minus i; 1 plus i,

108
00:06:37,620 --> 00:06:41,440
3 minus lambda's
going to be minus 1.

109
00:06:41,440 --> 00:06:43,590
And I'll call this
vector u_1 and u_2.

110
00:06:47,400 --> 00:06:51,170
And again, we want u_1 and
u_2 equal to 0-- or sorry,

111
00:06:51,170 --> 00:06:54,880
the matrix multiplied by
[u 1,  u 2] is equal to 0.

112
00:06:54,880 --> 00:06:57,010
And just by looking
at this again,

113
00:06:57,010 --> 00:06:59,440
we see that the second row is
actually a constant multiple

114
00:06:59,440 --> 00:07:01,440
of the first row.

115
00:07:01,440 --> 00:07:05,720
For example, if we were
to multiply this row

116
00:07:05,720 --> 00:07:08,367
by negative 2, and
this row by 1 plus i,

117
00:07:08,367 --> 00:07:10,200
we would see that they're
constant multiples

118
00:07:10,200 --> 00:07:11,790
of each other.

119
00:07:11,790 --> 00:07:22,110
So I can take u to be, for
example, 1, and 1 plus i.

120
00:07:22,110 --> 00:07:23,770
How did I get this?

121
00:07:23,770 --> 00:07:25,650
Well I just looked at
the second equation

122
00:07:25,650 --> 00:07:28,580
because it's a little
simpler, and I said, well,

123
00:07:28,580 --> 00:07:32,470
if I have 1 plus I here, I
can just say multiply it by 1.

124
00:07:32,470 --> 00:07:35,720
And then minus 1 times 1
plus i, when I add them up,

125
00:07:35,720 --> 00:07:37,380
is going to vanish.

126
00:07:37,380 --> 00:07:40,880
So this is how I
get the second one.

127
00:07:40,880 --> 00:07:43,020
Now there's something
curious going on,

128
00:07:43,020 --> 00:07:45,740
and this is going to be another
property of Hermitian matrices.

129
00:07:45,740 --> 00:07:48,540
But if you actually take a
look at this eigenvector,

130
00:07:48,540 --> 00:07:50,760
it will be orthogonal
to this eigenvector

131
00:07:50,760 --> 00:07:53,260
when we conjugate the
elements and dot the two

132
00:07:53,260 --> 00:07:54,594
vectors together.

133
00:07:54,594 --> 00:07:56,260
So this is another
very special property

134
00:07:56,260 --> 00:07:59,850
of complex Hermitian matrices.

135
00:08:02,550 --> 00:08:05,790
OK, so the last step now is to
construct these matrices lambda

136
00:08:05,790 --> 00:08:08,440
and S. Now we already
know what lambda

137
00:08:08,440 --> 00:08:12,000
is because it's the diagonal
matrix with the eigenvalues 1

138
00:08:12,000 --> 00:08:13,580
and 4.

139
00:08:13,580 --> 00:08:15,620
So we have 1, 0; 0 and 4.

140
00:08:21,860 --> 00:08:24,920
Now I'm going to do
something special for S.

141
00:08:24,920 --> 00:08:28,300
I've noted that these
two vectors u and v

142
00:08:28,300 --> 00:08:30,210
are orthogonal to each other.

143
00:08:30,210 --> 00:08:32,169
So what do I mean by orthogonal?

144
00:08:32,169 --> 00:08:35,990
Specifically, if I were to
take v conjugate transpose

145
00:08:35,990 --> 00:08:38,820
and multiply it by
u, we would end up

146
00:08:38,820 --> 00:08:45,370
getting 1 plus i minus 1.

147
00:08:45,370 --> 00:08:48,210
This would be v
conjugate transpose.

148
00:08:48,210 --> 00:08:54,940
1, 1 plus i, and we see that
when we multiply these out

149
00:08:54,940 --> 00:08:55,580
we get 0.

150
00:08:59,460 --> 00:09:01,370
So when we have
orthogonal eigenvectors,

151
00:09:01,370 --> 00:09:04,240
there's a trick that we can do
to build up this matrix S and S

152
00:09:04,240 --> 00:09:06,150
inverse.

153
00:09:06,150 --> 00:09:09,540
What we can do is we
can normalize u and v.

154
00:09:09,540 --> 00:09:14,210
So specifically, we can take any
constant multiple of u and v,

155
00:09:14,210 --> 00:09:16,584
and it's still going
to be an eigenvector.

156
00:09:16,584 --> 00:09:18,750
So what I'm going to do is
I'm going to take u and v

157
00:09:18,750 --> 00:09:22,020
and multiply them
by their length.

158
00:09:22,020 --> 00:09:27,420
So for example u, the amplitude
of its top component is 1.

159
00:09:27,420 --> 00:09:30,310
The amplitude of its
bottom component is 2.

160
00:09:30,310 --> 00:09:32,910
So notice that the modulus of
the complex number 1 plus I

161
00:09:32,910 --> 00:09:34,430
is 2.

162
00:09:34,430 --> 00:09:44,680
So we have-- sorry, it's root 2,
the complex modulus is root 2.

163
00:09:44,680 --> 00:09:48,990
So the amplitude of the
entire vector is root 3.

164
00:09:48,990 --> 00:09:52,741
It's 1 plus 2 squared quantity
square rooted, so it's root 3.

165
00:09:52,741 --> 00:09:54,240
So what we can do
is we can build up

166
00:09:54,240 --> 00:09:59,450
this matrix S using a
normalization factor of 1

167
00:09:59,450 --> 00:10:00,220
over root 3.

168
00:10:05,020 --> 00:10:10,520
And I'm going to take
the-- the first column is

169
00:10:10,520 --> 00:10:13,980
the first eigenvector that
corresponds to eigenvalue 1.

170
00:10:13,980 --> 00:10:18,120
And then the second column is
the second eigenvector which

171
00:10:18,120 --> 00:10:20,870
corresponds to eigenvalue 4.

172
00:10:20,870 --> 00:10:22,650
And the reason I
put in this root 3

173
00:10:22,650 --> 00:10:27,670
here is to make this column unit
length 1, and this column unit

174
00:10:27,670 --> 00:10:29,280
length 1.

175
00:10:29,280 --> 00:10:38,440
And the reason I do this is
because now this matrix S,

176
00:10:38,440 --> 00:10:42,550
it's possible to check that this
matrix S is actually unitary,

177
00:10:42,550 --> 00:10:50,520
which means that its inverse
is actually just equal to it's

178
00:10:50,520 --> 00:10:53,690
conjugate transpose.

179
00:10:53,690 --> 00:10:57,100
So this is a very special
property of the eigenvectors

180
00:10:57,100 --> 00:10:58,090
of a Hermitian matrix.

181
00:11:00,895 --> 00:11:02,770
And then lastly, I'm
just going to write down

182
00:11:02,770 --> 00:11:07,390
the diagonalization
of A. So if I have A,

183
00:11:07,390 --> 00:11:09,580
because I have its
eigenvector matrix S,

184
00:11:09,580 --> 00:11:12,320
and its eigenvalue
matrix lambda,

185
00:11:12,320 --> 00:11:16,300
it's possible to decompose A
into a product of S lambda S

186
00:11:16,300 --> 00:11:17,730
inverse.

187
00:11:17,730 --> 00:11:25,280
And because S is
unitary, its inverse

188
00:11:25,280 --> 00:11:29,940
is actually its
conjugate transpose.

189
00:11:29,940 --> 00:11:32,580
So just to put the
pieces together,

190
00:11:32,580 --> 00:11:41,520
we have A is equal to S-- which
is 1 over root 3 1 minus i,

191
00:11:41,520 --> 00:11:51,410
minus 1; 1, 1 plus i-- times
the diagonal matrix [1, 0; 0, 4]

192
00:11:51,410 --> 00:11:56,850
times S inverse, which is going
to be its conjugate transpose.

193
00:11:56,850 --> 00:11:59,850
So what I do is I conjugate
each element, so 1 minus i

194
00:11:59,850 --> 00:12:02,320
becomes 1 plus i and vice versa.

195
00:12:02,320 --> 00:12:04,530
And then I take the transpose.

196
00:12:04,530 --> 00:12:06,420
So I get 1 plus i.

197
00:12:06,420 --> 00:12:08,970
Transposing swaps
the minus 1 and 1.

198
00:12:12,090 --> 00:12:16,660
And at the end of the day, I get
S inverse is just this matrix

199
00:12:16,660 --> 00:12:19,120
here.

200
00:12:19,120 --> 00:12:21,870
And if you were to multiply
these matrices out,

201
00:12:21,870 --> 00:12:26,660
you would see it you
actually do recover A.

202
00:12:26,660 --> 00:12:29,900
So just to summarize
quickly, even though we

203
00:12:29,900 --> 00:12:33,760
were given a complex matrix A,
the process to diagonalize A

204
00:12:33,760 --> 00:12:35,580
is the same as what
we've seen before.

205
00:12:35,580 --> 00:12:38,770
The first step is to find
the characteristic equation

206
00:12:38,770 --> 00:12:39,950
and the eigenvalues.

207
00:12:39,950 --> 00:12:42,380
And then the second step is
to find the eigenvectors,

208
00:12:42,380 --> 00:12:44,580
and you do this in
the same procedure.

209
00:12:44,580 --> 00:12:48,150
But in general, the
eigenvectors can be complex.

210
00:12:48,150 --> 00:12:52,440
And for this very special
case, when A is Hermitian,

211
00:12:52,440 --> 00:12:54,530
the eigenvalues are real,
and the eigenvectors

212
00:12:54,530 --> 00:12:56,750
are orthogonal to each other.

213
00:12:56,750 --> 00:13:00,240
So I think I'll conclude here,
and I'll see you next time.